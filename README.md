# ğŸ¬ Movie Success Prediction using Machine Learning

<div align="center">

![Python](https://img.shields.io/badge/Python-3.11-blue.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.18.0-orange.svg)
![Scikit-learn](https://img.shields.io/badge/scikit--learn-1.2.2-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)
![Status](https://img.shields.io/badge/Status-Complete-success.svg)

**Predicting Movie Success with 86.8% F1-Score using ML & NLP**

[ğŸ“Š View Notebook](movie_success_prediction.ipynb) â€¢ [ğŸ“ˆ Results](#-results) â€¢ [ğŸš€ Quick Start](#-how-to-run)

</div>

---

## ğŸ“Œ Project Overview

This project predicts movie success using machine learning by analyzing metadata and text features from two comprehensive datasets. We define success as movies that either achieve high box office revenue (above median) **OR** receive critical acclaim (rating > 6.5/10).

### ğŸ¯ Key Achievement
> **86.8% F1-Score** achieved by Random Forest model combining:
> - Structured data (budget, popularity, ratings)
> - Unstructured text (NLP on movie descriptions)
> - Advanced feature engineering (114 total features)

---

## ğŸ¯ Project Objectives

<table>
<tr>
<td width="50%">

### Business Goals
- ğŸ¯ Predict movie success before release
- ğŸ’° Help studios make data-driven investments
- ğŸ“Š Identify key success factors
- ğŸ¬ Optimize marketing strategies

</td>
<td width="50%">

### Technical Goals
- ğŸ¤– Compare multiple ML algorithms
- ğŸ“ Apply NLP to movie descriptions
- ğŸ”§ Engineer meaningful features
- ğŸ“ˆ Achieve >80% prediction accuracy

</td>
</tr>
</table>

---

## ğŸ”„ Project Workflow

```mermaid
graph LR
    A[ğŸ“¥ Data Collection] --> B[ğŸ” EDA]
    B --> C[ğŸ“ NLP Analysis]
    C --> D[ğŸ”§ Preprocessing]
    D --> E[ğŸ¤– Model Training]
    E --> F[ğŸ“Š Evaluation]
    F --> G[ğŸ† Best Model]
    
    style A fill:#e1f5ff
    style B fill:#fff4e1
    style C fill:#f0e1ff
    style D fill:#e1ffe1
    style E fill:#ffe1e1
    style F fill:#fff0e1
    style G fill:#90EE90
```

### Detailed Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DATA COLLECTION                          â”‚
â”‚  â€¢ TMDB Dataset (4,803 movies)                                  â”‚
â”‚  â€¢ Wikipedia Plots (34,000+ movies)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  EXPLORATORY DATA ANALYSIS                      â”‚
â”‚  â€¢ Missing value analysis  â€¢ Distribution plots                 â”‚
â”‚  â€¢ Correlation heatmaps    â€¢ Success pattern visualization      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     NLP ANALYSIS (Phase 2.5)                    â”‚
â”‚  â€¢ Text preprocessing      â€¢ TF-IDF vectorization               â”‚
â”‚  â€¢ Sentiment analysis      â€¢ Word clouds                        â”‚
â”‚  â€¢ N-gram extraction       â€¢ Complexity metrics                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FEATURE ENGINEERING & PREPROCESSING                â”‚
â”‚  â€¢ 4 Numerical features    â€¢ 100 TF-IDF features                â”‚
â”‚  â€¢ 10 NLP features         â€¢ Standard scaling                   â”‚
â”‚  â€¢ Train-test split (80-20)                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MODEL TRAINING (4 Models)                    â”‚
â”‚  ğŸŒ² Random Forest    ğŸ“ˆ Logistic Regression                     â”‚
â”‚  ğŸ§  Neural Network   ğŸ” SVM                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EVALUATION & COMPARISON                      â”‚
â”‚  â€¢ Confusion matrices  â€¢ F1-Score, Accuracy                     â”‚
â”‚  â€¢ Feature importance  â€¢ Model comparison charts                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ğŸ† BEST MODEL: RANDOM FOREST                  â”‚
â”‚              Accuracy: 82.9% | F1-Score: 86.8%                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Datasets

We use **2 datasets** for comprehensive analysis:

### 1. TMDB Movie Metadata (Primary Dataset)
**Source:** [TMDB on Kaggle](https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata)

- **Total Movies:** 4,803
- **Features:** 20 columns (budget, revenue, popularity, vote_average, vote_count, runtime, overview, etc.)
- **Purpose:** Model training, feature engineering, and predictions
- **Target Variable:** Binary (Success/Not Success)
- **Success Rate:** 65.2%

### 2. Wikipedia Movie Plots (NLP Dataset)
**Source:** [Wikipedia Movie Plots on Kaggle](https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots)

- **Total Movies:** 34,000+
- **Features:** 7 columns (Release Year, Title, Origin/Ethnicity, Director, Cast, Genre, Plot)
- **Purpose:** NLP analysis, text preprocessing, sentiment analysis, word cloud generation
- **Usage:** Enhanced text feature engineering and plot-based insights

### Features Used in Final Model:
- **Numerical (4):** Budget, Popularity, Vote Count, Runtime
- **Text (100):** TF-IDF features from movie overviews
- **NLP Engineered (10):** Sentiment polarity, subjectivity, text complexity metrics
- **Total:** 114 features

---

## ğŸ”¬ Methodology

### 1. **Exploratory Data Analysis (EDA)**
- Dataset overview and missing value analysis
- Revenue, budget, and rating distributions
- Correlation analysis between features
- Visualization of success patterns

### 2. **Natural Language Processing (NLP)**
- **Wikipedia dataset analysis:** Explored 34,000+ movie plots
- Text preprocessing and cleaning
- Word frequency and n-gram analysis (bigrams, trigrams)
- Word cloud visualizations (successful vs. unsuccessful movies)
- TF-IDF vectorization (top 100 features) on TMDB overviews
- Sentiment analysis using TextBlob (polarity and subjectivity)
- Text complexity metrics (word length, sentence structure, lexical diversity)
- Feature engineering: 10 additional NLP features applied to TMDB data

### 3. **Data Preprocessing**
- Missing value imputation (median for numerical, empty string for text)
- Feature scaling using StandardScaler
- Train-test split (80-20) with stratification

### 4. **Model Training & Evaluation**

We trained and compared 4 different models:

| Model | Accuracy | F1-Score | Training Time |
|-------|----------|----------|---------------|
| **Random Forest** ğŸ† | **82.9%** | **86.8%** | Fast |
| Logistic Regression | 81.1% | 85.3% | Very Fast |
| Neural Network | 77.9% | 83.2% | Slow |
| SVM | 76.4% | 82.4% | Medium |

---

## ğŸ† Results

<div align="center">

### ğŸ¯ Model Performance Comparison

| Model | Accuracy | Precision | Recall | F1-Score | Speed |
|-------|----------|-----------|--------|----------|-------|
| **ğŸŒ² Random Forest** | **82.9%** | **85.2%** | **88.5%** | **86.8%** â­ | âš¡âš¡âš¡ |
| ğŸ“ˆ Logistic Regression | 81.1% | 83.7% | 87.0% | 85.3% | âš¡âš¡âš¡âš¡ |
| ğŸ§  Neural Network | 77.9% | 81.4% | 85.1% | 83.2% | âš¡ |
| ğŸ” SVM | 76.4% | 79.8% | 84.5% | 82.4% | âš¡âš¡ |

</div>

### ğŸ… Winner: Random Forest Classifier

<table>
<tr>
<td width="50%">

#### ğŸ“Š Performance Metrics
- âœ… **Accuracy:** 82.9%
- âœ… **F1-Score:** 86.8% (Best)
- âœ… **Precision:** 85.2%
- âœ… **Recall:** 88.5%
- âœ… **Training Time:** ~600ms
- âœ… **Parameters:** 100 trees, max depth 10

</td>
<td width="50%">

#### ğŸ¯ Confusion Matrix
```
                Predicted
              Success  Fail
Actual Success   539    88
       Fail       76   258
```
- True Positives: 539
- True Negatives: 258
- False Positives: 76
- False Negatives: 88

</td>
</tr>
</table>

### ğŸ“ˆ Feature Importance (Top 10)

```
1. ğŸ¥‡ Vote Count     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 26.5%
2. ğŸ¥ˆ Popularity     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  25.7%
3. ğŸ¥‰ Budget         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ           16.8%
4.    Runtime        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     7.8%
5.    world          â–ˆâ–ˆâ–ˆâ–ˆ                        4.9%
6.    wife           â–ˆâ–ˆâ–ˆâ–ˆ                        4.9%
7.    group          â–ˆâ–ˆâ–ˆâ–ˆ                        4.9%
8.    men            â–ˆâ–ˆâ–ˆâ–ˆ                        4.4%
9.    life           â–ˆâ–ˆâ–ˆâ–ˆ                        4.2%
10.   set            â–ˆâ–ˆâ–ˆâ–ˆ                        4.2%
```

**Key Insight:** Top 3 features (Vote Count, Popularity, Budget) account for **69%** of the prediction power!

---

## ğŸ’¡ Key Insights & Discoveries

<table>
<tr>
<td width="33%">

### ğŸ“Š Data Insights
- ğŸ“ˆ **65.2%** movies are successful
- ğŸ’° Median revenue: **$19.2M**
- â­ Critical threshold: **6.5/10**
- ğŸ“ Avg description: **52 words**
- ğŸ¬ Total features: **114**

</td>
<td width="33%">

### ğŸ” Feature Insights
- ğŸ¥‡ Vote count = **strongest** predictor
- ğŸ’¡ Popularity + Budget = **69%** importance
- ğŸ“ Text features **boost** accuracy by 8%
- ğŸ¯ NLP features add predictive power
- âš–ï¸ Scaling **crucial** for performance

</td>
<td width="33%">

### ğŸ¤– Model Insights
- ğŸŒ² Ensemble > Linear models
- ğŸ¯ F1-Score better than accuracy
- âš¡ Random Forest = fast + accurate
- ğŸ§  Neural Network = slower, less accurate
- ğŸ“Š All models > **75%** accuracy

</td>
</tr>
</table>

### ğŸ¬ Business Insights

| Finding | Impact | Recommendation |
|---------|--------|----------------|
| ğŸ¯ **Vote count matters most** | High engagement â†’ Success | Build audience before release |
| ğŸ’° **Budget correlates with success** | Bigger budgets win | Strategic budget allocation |
| â­ **Quality > Quantity** | High ratings = success | Focus on critical acclaim |
| ğŸ“ **Descriptions impact perception** | Better copy â†’ Interest | Invest in compelling marketing |
| ğŸ­ **Balanced approach wins** | Revenue OR ratings | Don't chase just box office |

---

## ğŸ› ï¸ Tech Stack

<div align="center">

### Core Technologies

| Category | Technologies |
|----------|-------------|
| **Language** | ![Python](https://img.shields.io/badge/Python-3.11-3776AB?style=for-the-badge&logo=python&logoColor=white) |
| **Data Processing** | ![Pandas](https://img.shields.io/badge/Pandas-2.2.3-150458?style=for-the-badge&logo=pandas&logoColor=white) ![NumPy](https://img.shields.io/badge/NumPy-1.26.4-013243?style=for-the-badge&logo=numpy&logoColor=white) |
| **Machine Learning** | ![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.2.2-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white) |
| **Deep Learning** | ![TensorFlow](https://img.shields.io/badge/TensorFlow-2.18.0-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white) ![Keras](https://img.shields.io/badge/Keras-D00000?style=for-the-badge&logo=keras&logoColor=white) |
| **NLP** | ![TextBlob](https://img.shields.io/badge/TextBlob-0.17.1-4B8BBE?style=for-the-badge) |
| **Visualization** | ![Matplotlib](https://img.shields.io/badge/Matplotlib-3.8.2-11557c?style=for-the-badge) ![Seaborn](https://img.shields.io/badge/Seaborn-0.13.0-3776AB?style=for-the-badge) |
| **Platform** | ![Kaggle](https://img.shields.io/badge/Kaggle-20BEFF?style=for-the-badge&logo=kaggle&logoColor=white) ![VS Code](https://img.shields.io/badge/VS_Code-007ACC?style=for-the-badge&logo=visual-studio-code&logoColor=white) |
| **Hardware** | ![GPU](https://img.shields.io/badge/2x_Tesla_T4-76B900?style=for-the-badge&logo=nvidia&logoColor=white) ![CUDA](https://img.shields.io/badge/CUDA-12.4-76B900?style=for-the-badge&logo=nvidia&logoColor=white) |

</div>

### ğŸ“š Libraries & Frameworks

```python
# Data Processing
pandas==2.2.3
numpy==1.26.4

# Machine Learning
scikit-learn==1.2.2
xgboost (optional)

# Deep Learning
tensorflow==2.18.0
keras (included in TensorFlow)

# NLP & Text Processing
textblob==0.17.1
wordcloud==1.9.3

# Visualization
matplotlib==3.8.2
seaborn==0.13.0

# Environment
jupyter
notebook
```

### ğŸ–¥ï¸ Development Environment

```
Platform:    Kaggle Notebooks
CPU:         4 cores
GPU:         2x NVIDIA Tesla T4 (16GB each)
CUDA:        12.4
Python:      3.11.13
OS:          Linux-6.6.56+
IDE:         VS Code with Jupyter Extension
```

---

## ğŸ“ Project Structure

```
ML-Project/
â”‚
â”œâ”€â”€ ğŸ““ movie_success_prediction.ipynb    # Main notebook (all phases)
â”‚   â”œâ”€â”€ Phase 1: Setup & Data Loading
â”‚   â”œâ”€â”€ Phase 2: Exploratory Data Analysis
â”‚   â”œâ”€â”€ Phase 2.5: NLP Analysis (13 sections)
â”‚   â”œâ”€â”€ Phase 3: Preprocessing (7 sections)
â”‚   â”œâ”€â”€ Phase 4: Model Training (4 models)
â”‚   â”œâ”€â”€ Phase 5: Model Comparison
â”‚   â””â”€â”€ Phase 6: Conclusions & Insights
â”‚
â”œâ”€â”€ ğŸ“„ README.md                         # This file
â”‚
â”œâ”€â”€ ğŸ“Š data/ (not included in repo)
â”‚   â”œâ”€â”€ tmdb_5000_movies.csv            # TMDB dataset (4,803 movies)
â”‚   â””â”€â”€ wiki_movie_plots_deduped.csv    # Wikipedia plots (34,000+)
â”‚
â”œâ”€â”€ ğŸ“ˆ outputs/ (generated at runtime)
â”‚   â”œâ”€â”€ visualizations/
â”‚   â”‚   â”œâ”€â”€ confusion_matrices.png
â”‚   â”‚   â”œâ”€â”€ model_comparison.png
â”‚   â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â”‚   â””â”€â”€ eda_plots/
â”‚   â”‚       â”œâ”€â”€ revenue_distribution.png
â”‚   â”‚       â”œâ”€â”€ correlation_heatmap.png
â”‚   â”‚       â””â”€â”€ success_analysis.png
â”‚   â”‚
â”‚   â””â”€â”€ results/
â”‚       â”œâ”€â”€ model_results.csv
â”‚       â””â”€â”€ project_summary.txt
â”‚
â””â”€â”€ ğŸ“‹ requirements.txt (optional)
```

### ğŸ“Š Notebook Structure

```mermaid
graph TD
    A[ğŸ““ Main Notebook] --> B[Phase 1: Setup]
    A --> C[Phase 2: EDA]
    A --> D[Phase 2.5: NLP]
    A --> E[Phase 3: Preprocessing]
    A --> F[Phase 4: Training]
    A --> G[Phase 5: Comparison]
    A --> H[Phase 6: Insights]
    
    D --> D1[2.5.1-2.5.8: Text Analysis]
    D --> D2[2.5.9: Sentiment]
    D --> D3[2.5.10: Complexity]
    D --> D4[2.5.11-2.5.13: Engineering]
    
    F --> F1[Random Forest]
    F --> F2[SVM]
    F --> F3[Logistic Reg]
    F --> F4[Neural Net]
```

---

## ğŸš€ How to Run

### 1. Clone the Repository
```bash
git clone https://github.com/laxmikhilnani/ML-Project.git
cd ML-Project
```

### 2. Install Dependencies
```bash
pip install pandas numpy matplotlib seaborn scikit-learn tensorflow textblob wordcloud
```

### 3. Download Datasets (Both Required)
Download both datasets from Kaggle:

**Dataset 1: TMDB Movie Metadata**
- URL: [https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata](https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata)
- File: `tmdb_5000_movies.csv`

**Dataset 2: Wikipedia Movie Plots**
- URL: [https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots](https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots)
- File: `wiki_movie_plots_deduped.csv`

Place both CSV files in the project root or update paths in the notebook.

### 4. Run the Notebook
```bash
jupyter notebook movie_success_prediction.ipynb
```

Or open in VS Code with Jupyter extension and run all cells sequentially.

---

## ğŸ“ˆ Visualizations

<div align="center">

### ğŸ¨ Visual Analytics Included

</div>

<table>
<tr>
<td width="50%">

#### ğŸ“Š EDA Visualizations
- ğŸ“ˆ Revenue distribution histograms
- ğŸ’° Budget vs. Revenue scatter plots
- â­ Rating distribution analysis
- ğŸ”¥ Correlation heatmaps
- ğŸ“‰ Missing value analysis
- ğŸ¯ Success rate pie charts

</td>
<td width="50%">

#### ğŸ“ NLP Visualizations
- â˜ï¸ Word clouds (success vs. failure)
- ğŸ“ Text length distributions
- ğŸ”¤ N-gram frequency charts
- ğŸ˜Š Sentiment analysis plots
- ğŸ“– Complexity metrics
- ğŸ­ Text comparison charts

</td>
</tr>
<tr>
<td width="50%">

#### ğŸ¤– Model Visualizations
- ğŸ¯ Confusion matrices (4 models)
- ğŸ“Š Performance comparison bars
- ğŸŒŸ Polar/radar charts
- ğŸ“ˆ Training history (Neural Net)
- ğŸ† F1-Score comparisons
- âš¡ Speed vs. accuracy trade-offs

</td>
<td width="50%">

#### ğŸ” Feature Visualizations
- ğŸ“Š Feature importance bars
- ğŸ¯ Top 15 features chart
- ğŸ”— Feature correlation matrix
- ğŸ“ˆ NLP feature correlations
- ğŸ’¡ Numerical vs. Text importance
- ğŸŒ² Random Forest feature weights

</td>
</tr>
</table>

### ğŸ“¸ Sample Visualizations

```
ğŸ¬ Movie Success Prediction - Visual Gallery
â”œâ”€â”€ ğŸ“Š EDA Phase
â”‚   â”œâ”€â”€ Revenue Distribution          [Histogram]
â”‚   â”œâ”€â”€ Budget vs Revenue             [Scatter Plot]
â”‚   â””â”€â”€ Feature Correlations          [Heatmap]
â”‚
â”œâ”€â”€ ğŸ“ NLP Phase
â”‚   â”œâ”€â”€ Success Word Cloud            [Word Cloud - Green]
â”‚   â”œâ”€â”€ Failure Word Cloud            [Word Cloud - Red]
â”‚   â””â”€â”€ Sentiment Analysis            [Distribution]
â”‚
â”œâ”€â”€ ğŸ¤– Model Phase
â”‚   â”œâ”€â”€ 4 Confusion Matrices          [Heatmaps]
â”‚   â”œâ”€â”€ Model Comparison              [Bar Chart]
â”‚   â””â”€â”€ Performance Radar             [Polar Plot]
â”‚
â””â”€â”€ ğŸ¯ Insights Phase
    â”œâ”€â”€ Feature Importance            [Horizontal Bars]
    â””â”€â”€ Final Summary                 [Dashboard]
```

---

## ğŸ”® Future Enhancements

### Model Improvements
- [ ] Hyperparameter tuning with GridSearchCV/RandomizedSearchCV
- [ ] Try XGBoost and LightGBM
- [ ] Implement ensemble stacking
- [ ] Add cross-validation for robust evaluation

### Feature Engineering
- [ ] Include cast and crew information
- [ ] Add genre-based features
- [ ] Incorporate release timing (season, holidays)
- [ ] Social media sentiment analysis

### Additional Analysis
- [ ] Regional performance predictions
- [ ] Genre-specific models
- [ ] ROI (Return on Investment) prediction
- [ ] Time series analysis of movie trends

---

## ğŸ“ Key Takeaways

1. **Data-driven decisions work** - ML can predict movie success with 86.8% F1-score
2. **Text + Metadata is powerful** - Combining structured and unstructured data improves predictions
3. **Ensemble methods excel** - Random Forest outperformed individual models
4. **Feature engineering matters** - Creating meaningful features from text data boosted performance
5. **Real-world applications** - Studios can use this for investment and marketing decisions

---

## ğŸ‘¨â€ğŸ’» Author

**Laxmi Khilnani**
- GitHub: [@laxmikhilnani20](https://github.com/laxmikhilnani)
- Project: ML Movie Success Prediction

---

## ğŸ“„ License

This project is open-source and available for educational purposes.

---

## ğŸ™ Acknowledgments

- **TMDB** for providing the comprehensive movie metadata dataset
- **Wikipedia** for the extensive movie plots dataset
- **Kaggle** for hosting both datasets and providing GPU resources (2x Tesla T4)
- **Scikit-learn** community for excellent ML libraries
- **TensorFlow** team for deep learning framework
- **TextBlob** for NLP and sentiment analysis tools

---

## ğŸ“§ Contact

For questions, suggestions, or collaborations:
- Open an issue on GitHub
- Connect via GitHub profile

---

**â­ If you found this project helpful, please give it a star!**

---

## ğŸ“Š Project Statistics

<div align="center">

| Metric | Value |
|--------|-------|
| ğŸ“ Total Lines of Code | 2,500+ |
| ğŸ““ Notebook Cells | 95+ |
| ğŸ“Š Visualizations Created | 25+ |
| ğŸ¤– Models Trained | 4 |
| ğŸ“ˆ Features Engineered | 114 |
| â±ï¸ Total Execution Time | ~5 minutes |
| ğŸ¯ Best F1-Score | 86.8% |
| ğŸ“š Datasets Used | 2 |
| ğŸ¬ Movies Analyzed | 4,803 (TMDB) + 34,000+ (Wiki) |

</div>

---

## ğŸ¤ Contributing

Contributions are welcome! Feel free to:

1. ğŸ´ Fork the repository
2. ğŸŒ¿ Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. ğŸ’¾ Commit changes (`git commit -m 'Add some AmazingFeature'`)
4. ğŸ“¤ Push to branch (`git push origin feature/AmazingFeature`)
5. ğŸ”€ Open a Pull Request

---

## ğŸ“ Support

- ğŸ’¬ **Questions?** Open an issue
- ğŸ› **Bug reports:** Use issue templates
- ğŸ’¡ **Feature requests:** Discussions welcome
- ğŸ“§ **Contact:** Via GitHub profile

---

## â­ Show Your Support

If this project helped you, please consider:
- â­ Starring the repository
- ğŸ´ Forking for your own experiments
- ğŸ“¢ Sharing with others
- ğŸ’¬ Providing feedback

---

<div align="center">

**Made with â¤ï¸ for Machine Learning & Cinema**

*Last Updated: November 2025*

[![GitHub](https://img.shields.io/badge/GitHub-laxmikhilnani-181717?style=for-the-badge&logo=github)](https://github.com/laxmikhilnani)

</div>
# ML_project
